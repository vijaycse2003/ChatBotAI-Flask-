{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41499dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input,Embedding,LSTM,Dense,GlobalMaxPooling1D,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13ba114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('content.json') as content:\n",
    "    data1=json.load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb26d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=[]\n",
    "inputs=[]\n",
    "responses={}\n",
    "\n",
    "for intent in data1['intents']:\n",
    "    responses[intent['tag']]=intent['responses']\n",
    "    for lines in intent['patterns']:\n",
    "        inputs.append(lines)\n",
    "        tag.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebd6aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good day</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>ragging against</td>\n",
       "      <td>ragging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>antiragging facility</td>\n",
       "      <td>ragging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>ragging juniors</td>\n",
       "      <td>ragging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>ragging history</td>\n",
       "      <td>ragging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ragging incidents</td>\n",
       "      <td>ragging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   inputs      tags\n",
       "0                      Hi  greeting\n",
       "1            How are you?  greeting\n",
       "2        Is anyone there?  greeting\n",
       "3                   Hello  greeting\n",
       "4                Good day  greeting\n",
       "..                    ...       ...\n",
       "363       ragging against   ragging\n",
       "364  antiragging facility   ragging\n",
       "365       ragging juniors   ragging\n",
       "366       ragging history   ragging\n",
       "367     ragging incidents   ragging\n",
       "\n",
       "[368 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame({\"inputs\":inputs,\"tags\":tag})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf07aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7716b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>canteen facility</td>\n",
       "      <td>canteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>events organised</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>whats your name</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>cse lab</td>\n",
       "      <td>LabDetails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>facilities</td>\n",
       "      <td>facilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>good work</td>\n",
       "      <td>salutaion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>sem</td>\n",
       "      <td>sem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>sports facilities</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>what is name of aamec founder</td>\n",
       "      <td>Founder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>what am i chatting to</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            inputs        tags\n",
       "208               canteen facility     canteen\n",
       "168               events organised       event\n",
       "28                 whats your name        name\n",
       "161                        cse lab  LabDetails\n",
       "282                     facilities  facilities\n",
       "..                             ...         ...\n",
       "348                      good work   salutaion\n",
       "240                            sem         sem\n",
       "335              sports facilities      sports\n",
       "80   what is name of aamec founder     Founder\n",
       "32           what am i chatting to        name\n",
       "\n",
       "[368 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "data['inputs']=data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "data['inputs']=data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3b21a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208       canteen\n",
      "168         event\n",
      "28           name\n",
      "161    LabDetails\n",
      "282    facilities\n",
      "          ...    \n",
      "348     salutaion\n",
      "240           sem\n",
      "335        sports\n",
      "80        Founder\n",
      "32           name\n",
      "Name: tags, Length: 368, dtype: object\n",
      "[20 23 33  7 24 19 42 28 28 35 34 34 26 45  0  3 45 32 41 19 20 35 25 21\n",
      " 38 27 35 40 40 45 34 30 31  8 40 30 20 36 26 11 24 14 33 30 39 37 39 30\n",
      "  5  8 41 40  0 25 18 30 16 43 40 26 41 28 37 13 33 22 28 23 26 20 46 40\n",
      " 30 44 20 35 20 25 40 40 40 40 17 20 46 34 22 43 38 12 25 37 19 28 44 20\n",
      "  2 19 15 30 38 43 33 37  6 28 33 34 15 45 46 46 44 23 46  2 34 43 10  7\n",
      " 35 33 27 41 34 39  0 25 34 14 30 31 44 16 30 31 27  0 25 13 30 40 11  1\n",
      " 37 46 32  3 12 16 13 22 37 35 39 11 39 32 23 16 13 18 17 33 39 23  8 40\n",
      "  2  6 39 22 23 37 26 12 21 10 40 40 34  7 36 35 23 12 34 26 30  5 34 27\n",
      " 28  2  1 19 35 28  5 15 23  5 31 18 40 34 37 20 16 34 46 34 26 34 24 40\n",
      " 18 40 35 40  4 21 45 46 27 13 28 12 17 33 44 19 39 16 28 26 23 46 10 41\n",
      " 33 26 41 37  4 18 14 32 21 41 42 11 40 23 45 14 40 28 10  6 24 39 40 41\n",
      " 28 28 41 25 44 31 40 21  3 11 21 17 40 42 30 27 23 30 45 31  8 28 34 42\n",
      " 11 39 35 43 42 10 46  8 30 40 40 34 22 16 20 24 29 39 35  5 30 11 20 41\n",
      " 45 42 35 26 33  0 32 27 33 33 22 21 45 46 11 17 26 21 29  9  4 27 27 32\n",
      " 46 43 32 11 28 40 30 43 28  4 16 15  9 30 21 29 36 28 27 43 26 39 16 34\n",
      " 43 37 36 39 41 42  3 33]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer(num_words=2000)\n",
    "t=tokenizer.fit_on_texts(data['inputs'])\n",
    "train=tokenizer.texts_to_sequences(data['inputs'])\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train=pad_sequences(train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "y_train=le.fit_transform(data['tags'])\n",
    "print(data['tags'])\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd4a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "input_shape=x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ad6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'college': 1, 'is': 2, 'what': 3, 'of': 4, 'cse': 5, 'the': 6, 'aamec': 7, 'and': 8, 'are': 9, 'scholarship': 10, 'you': 11, 'how': 12, 'fees': 13, 'in': 14, 'library': 15, 'quota': 16, 'about': 17, 'i': 18, '2023': 19, 'when': 20, 'courses': 21, 'can': 22, 'there': 23, 'facilities': 24, 'to': 25, 'number': 26, 'for': 27, 'government': 28, 'canteen': 29, 'events': 30, 'name': 31, '2024': 32, 'have': 33, 'exam': 34, 'engineering': 35, 'departments': 36, 'graduate': 37, 'ragging': 38, 'do': 39, 'many': 40, 'facility': 41, 'your': 42, 'sports': 43, 'timing': 44, 'any': 45, 'me': 46, 'management': 47, 'pg': 48, 'first': 49, 'ug': 50, 'admission': 51, 'who': 52, 'uniform': 53, 'placement': 54, 'semester': 55, 'list': 56, 'programme': 57, 'details': 58, 'companies': 59, 'contact': 60, 'bus': 61, 'food': 62, 'available': 63, 'information': 64, '2022': 65, 'hod': 66, 'year': 67, 'where': 68, 'does': 69, 'committee': 70, 'holidays': 71, 'process': 72, 'infrastructure': 73, 'founder': 74, 'will': 75, 'location': 76, 'scst': 77, 'floors': 78, 'tell': 79, 'vision': 80, 'mission': 81, 'should': 82, 'staffs': 83, 'call': 84, 'objectives': 85, 'phone': 86, 'good': 87, 'seats': 88, 'approved': 89, 'whats': 90, 'lab': 91, 'hours': 92, 'we': 93, 'chemical': 94, 'principal': 95, 'civil': 96, 'psos': 97, 'it': 98, 'mechanical': 99, 'no': 100, 'pos': 101, 'a': 102, 'cafetaria': 103, 'hostel': 104, 'contacts': 105, 'am': 106, 'get': 107, 'structure': 108, 'branch': 109, 'peos': 110, 'bye': 111, 'open': 112, 'organised': 113, 'visit': 114, 'info': 115, 'see': 116, 'wear': 117, 'routes': 118, 'menu': 119, 'size': 120, 'maximum': 121, 'students': 122, 'intake': 123, 'books': 124, 'ok': 125, 'timetable': 126, 'undergraduate': 127, 'different': 128, 'later': 129, 'holiday': 130, 'building': 131, 'computer': 132, 'love': 133, 'done': 134, 'up': 135, 'antiragging': 136, 'vacation': 137, 'educational': 138, 'work': 139, 'u': 140, 'specific': 141, 'give': 142, 'history': 143, 'conducted': 144, 'day': 145, 'each': 146, 'package': 147, 'outcomes': 148, 'which': 149, 'thanks': 150, 'help': 151, 'dates': 152, 'provide': 153, 'games': 154, 'postgraduate': 155, 'on': 156, 'operation': 157, 'casuals': 158, 'schedule': 159, 'campus': 160, 'marry': 161, 'ya': 162, 'comps': 163, 'dress': 164, 'code': 165, 'goodbye': 166, 'called': 167, 'its': 168, 'juniors': 169, 'okk': 170, 'bitch': 171, 'ce': 172, 'ttyl': 173, 'cases': 174, 'committe': 175, 'these': 176, 'things': 177, 'aiml': 178, 'fourth': 179, 'end': 180, 'idiot': 181, 'here': 182, 'take': 183, 'attend': 184, 'why': 185, 'use': 186, 'shut': 187, 'something': 188, 'department': 189, 'dresscode': 190, 'thing': 191, 'functions': 192, 'fucker': 193, 'taking': 194, 'anyone': 195, 'nice': 196, 'much': 197, 'frst': 198, 'direction': 199, 'libraries': 200, 'hello': 201, 'starting': 202, 'pickup': 203, 'points': 204, 'practice': 205, 'active': 206, 'long': 207, 'be': 208, 'eat': 209, 'recruitment': 210, 'okie': 211, 'k': 212, 'foods': 213, 'well': 214, 'okay': 215, 'event': 216, 'held': 217, 'at': 218, 'average': 219, 'more': 220, 'book': 221, 'my': 222, 'time': 223, 'comes': 224, 'science': 225, 'map': 226, 'second': 227, 'telephone': 228, 'talk': 229, 'provided': 230, 'per': 231, 'hi': 232, 'come': 233, 'cya': 234, 'leaving': 235, 'incidents': 236, 'variety': 237, 'max': 238, 'an': 239, 'quotafirst': 240, 'guys': 241, 'job': 242, 'third': 243, 'working': 244, 'days': 245, 'tall': 246, 'unis': 247, 'scholarships': 248, 'stundent': 249, 'taken': 250, 'activities': 251, 'collections': 252, 'located': 253, 'please': 254, 'stupid': 255, 'resources': 256, 'this': 257, 'seat': 258, 'allotment': 259, 'vacations': 260, 'gtg': 261, 'heyy': 262, 'starts': 263, 'fuck': 264, 'automobile': 265, 'dumb': 266, 'ass': 267, 'saturday': 268, 'head': 269, 'whatsup': 270, 'asshole': 271, 'got': 272, 'go': 273, 'thank': 274, 'hell': 275, 'against': 276, 'our': 277, 'sem': 278, 'chatting': 279}\n",
      "number of unquie words 279\n",
      "Output length  47\n"
     ]
    }
   ],
   "source": [
    "vocabulary=len(tokenizer.word_index)\n",
    "print(tokenizer.word_index)\n",
    "print('number of unquie words',vocabulary)\n",
    "\n",
    "output_length=le.classes_.shape[0]\n",
    "print('Output length ',output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f14cecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model\n",
    "\n",
    "\n",
    "i=Input(shape=(input_shape,))\n",
    "x=Embedding(vocabulary+1,10)(i)\n",
    "x=LSTM(10,return_sequences=True)(x)\n",
    "x=Flatten()(x)\n",
    "x=Dense(output_length,activation='softmax')(x)\n",
    "model=Model(i,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dcf6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60645be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 3s 9ms/step - loss: 3.8458 - accuracy: 0.0272\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.8296 - accuracy: 0.0543\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.8014 - accuracy: 0.0543\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.7491 - accuracy: 0.0598\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.6859 - accuracy: 0.0842\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.6573 - accuracy: 0.0707\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.6396 - accuracy: 0.0707\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.6236 - accuracy: 0.0761\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.6089 - accuracy: 0.0761\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5901 - accuracy: 0.0788\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5706 - accuracy: 0.0842\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5520 - accuracy: 0.0897\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5298 - accuracy: 0.0897\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5005 - accuracy: 0.0951\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4737 - accuracy: 0.0951\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4429 - accuracy: 0.0951\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4099 - accuracy: 0.0951\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.3779 - accuracy: 0.0924\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.3434 - accuracy: 0.1033\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.3029 - accuracy: 0.1168\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2617 - accuracy: 0.1168\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2178 - accuracy: 0.1223\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.1728 - accuracy: 0.1440\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1224 - accuracy: 0.1630\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.0749 - accuracy: 0.1739\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.0239 - accuracy: 0.1712\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.9679 - accuracy: 0.1902\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.9133 - accuracy: 0.2038\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.8591 - accuracy: 0.2337\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.8056 - accuracy: 0.2500\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.7488 - accuracy: 0.2663\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.6951 - accuracy: 0.2989\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.6477 - accuracy: 0.3261\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.6097 - accuracy: 0.3288\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.5524 - accuracy: 0.3505\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.5096 - accuracy: 0.3505\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4609 - accuracy: 0.3641\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.4169 - accuracy: 0.3750\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3781 - accuracy: 0.3804\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3418 - accuracy: 0.3995\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3097 - accuracy: 0.4185\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2601 - accuracy: 0.4185\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.2310 - accuracy: 0.4103\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1873 - accuracy: 0.4158\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1466 - accuracy: 0.4592\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1102 - accuracy: 0.4891\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0704 - accuracy: 0.4891\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0358 - accuracy: 0.4810\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0009 - accuracy: 0.4918\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9656 - accuracy: 0.5027\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.9281 - accuracy: 0.5543\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.8953 - accuracy: 0.5707\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.8623 - accuracy: 0.5625\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8349 - accuracy: 0.5625\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.7995 - accuracy: 0.5897\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7696 - accuracy: 0.6196\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7389 - accuracy: 0.6359\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.7048 - accuracy: 0.6277\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.6758 - accuracy: 0.6060\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6462 - accuracy: 0.6440\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6205 - accuracy: 0.6576\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5961 - accuracy: 0.6413\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.5628 - accuracy: 0.6658\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.5360 - accuracy: 0.6957\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5101 - accuracy: 0.6957\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4849 - accuracy: 0.6821\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4548 - accuracy: 0.7011\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4318 - accuracy: 0.6984\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.4113 - accuracy: 0.6984\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3914 - accuracy: 0.7065\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3678 - accuracy: 0.7065\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3416 - accuracy: 0.7120\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3202 - accuracy: 0.7364\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3024 - accuracy: 0.7473\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2764 - accuracy: 0.7446\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2546 - accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2347 - accuracy: 0.7663\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.2114 - accuracy: 0.7717\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1922 - accuracy: 0.7717\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1808 - accuracy: 0.7853\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1629 - accuracy: 0.7799\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1357 - accuracy: 0.7962\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1168 - accuracy: 0.8125\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1023 - accuracy: 0.8016\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0874 - accuracy: 0.8016\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0666 - accuracy: 0.8125\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0500 - accuracy: 0.8179\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0334 - accuracy: 0.8207\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0162 - accuracy: 0.8152\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.0017 - accuracy: 0.8261\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9871 - accuracy: 0.8179\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9718 - accuracy: 0.8397\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.9578 - accuracy: 0.8451\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9395 - accuracy: 0.8342\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.9281 - accuracy: 0.8315\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9108 - accuracy: 0.8614\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8985 - accuracy: 0.8478\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8848 - accuracy: 0.8560\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8747 - accuracy: 0.8505\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.8671 - accuracy: 0.8424\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8567 - accuracy: 0.8587\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.8383 - accuracy: 0.8560\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8184 - accuracy: 0.8696\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.8131 - accuracy: 0.8614\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7987 - accuracy: 0.8668\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7820 - accuracy: 0.8723\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7732 - accuracy: 0.8641\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7615 - accuracy: 0.8750\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7482 - accuracy: 0.8832\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7435 - accuracy: 0.8723\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7279 - accuracy: 0.8777\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7216 - accuracy: 0.8859\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7116 - accuracy: 0.8859\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.8859\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.8832\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.8777\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.8886\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6649 - accuracy: 0.8995\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6549 - accuracy: 0.8967\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6411 - accuracy: 0.8995\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6399 - accuracy: 0.9049\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6277 - accuracy: 0.8940\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6209 - accuracy: 0.8995\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6086 - accuracy: 0.9022\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.9022\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5924 - accuracy: 0.9158\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.9185\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5781 - accuracy: 0.9103\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5704 - accuracy: 0.9103\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5623 - accuracy: 0.9239\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5537 - accuracy: 0.9239\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.9158\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.9158\n",
      "Epoch 134/200\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 0.5432 - accuracy: 0.9258"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15212\\538717637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1692\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \"\"\"\n\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \"\"\"\n\u001b[0;32m   1159\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1124\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d573d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x00000246A45F6520>\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,render_template,redirect,request,jsonify\n",
    "from flask_ngrok import run_with_ngrok\n",
    "import random\n",
    "\n",
    "print(model)\n",
    "\n",
    "def generate_res(prediction_input):\n",
    "    \n",
    "    texts_p=[]\n",
    "  \n",
    "    \n",
    "    prediction_input=[letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "    prediction_input=''.join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    \n",
    "    print(prediction_input)\n",
    "    \n",
    "    \n",
    "    prediction_input=tokenizer.texts_to_sequences(texts_p)\n",
    "    prediction_input=np.array( prediction_input).reshape(-1)\n",
    "    prediction_input=pad_sequences([prediction_input],input_shape)\n",
    "    \n",
    "    output=model.predict(prediction_input)\n",
    "    output=output.argmax()\n",
    "  \n",
    "    \n",
    "    response_tag=le.inverse_transform([output])[0]\n",
    "    response_tag=le.inverse_transform([output])[0]\n",
    "    res=random.choice(responses[response_tag])\n",
    "    print(f\"HackAI ({response_tag}) :\",res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://4937-2401-4900-4844-d585-c66-dfff-ff2a-c761.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:49:18] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Sep/2023 10:49:19] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Sep/2023 10:49:21] \"GET /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "principal\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:51:15] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (infrastructure) : Our University has Excellent Infrastructure. Campus is clean. Good IT Labs With Good Speed of Internet connection\n",
      "Message  --> principal\n",
      "Our University has Excellent Infrastructure. Campus is clean. Good IT Labs With Good Speed of Internet connection\n",
      "principal name\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:51:44] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (principle) : Dr.S.N. Ramasamy is having 20 years of experience in teaching and Research besides 11 years of experience in building construction & infrastructure management\n",
      "Message  --> principal name\n",
      "Dr.S.N. Ramasamy is having 20 years of experience in teaching and Research besides 11 years of experience in building construction & infrastructure management\n",
      "founder name\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:51:54] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (Founder) : Thiru.M. Namasivayam Founder-Chairman of Anjalai Ammal-Mahalingam Engineering College was born on March 15, 1927 at Thanjavur in the South Indian state of Tamil Nadu. He was blessed with three daughters and a son. He started his career as a clerk in the Railway department. Due to his Zeal and hard work, he acquitted himself with credit and earned the appreciation of senior officers. His indefatigable energy and administrative ability marked him out for appointment as auditor in Southern Railway. His thoroughness and devotion to duty marked him to the prestigious position of General Secretary, Southern Railway Mazdoor Union. As a General Secretary, he had to toil hard to uplift the living standard and working environment of Railway Mazdoors.\n",
      "Message  --> founder name\n",
      "Thiru.M. Namasivayam Founder-Chairman of Anjalai Ammal-Mahalingam Engineering College was born on March 15, 1927 at Thanjavur in the South Indian state of Tamil Nadu. He was blessed with three daughters and a son. He started his career as a clerk in the Railway department. Due to his Zeal and hard work, he acquitted himself with credit and earned the appreciation of senior officers. His indefatigable energy and administrative ability marked him out for appointment as auditor in Southern Railway. His thoroughness and devotion to duty marked him to the prestigious position of General Secretary, Southern Railway Mazdoor Union. As a General Secretary, he had to toil hard to uplift the living standard and working environment of Railway Mazdoors.\n",
      "aamec details\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:52:43] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (aboutclg) : Anjalai Ammal Mahalingam Engineering College (AAMEC) stands, as a beacon light in brick and mortar, men and materials, involved in learning and teaching of Technical education. It fulfils its illustrious founder and veteran railway union leader Shri.M.Namasivayam's scintillating dream and ennobling vision and to establish a temple of learning far from the maddening crowd of the cities and yet having all the facilities of a well developed urban campus imparting technical education at international standards, accessible to students from far and near, rich and poor alike\n",
      "Message  --> aamec details\n",
      "Anjalai Ammal Mahalingam Engineering College (AAMEC) stands, as a beacon light in brick and mortar, men and materials, involved in learning and teaching of Technical education. It fulfils its illustrious founder and veteran railway union leader Shri.M.Namasivayam's scintillating dream and ennobling vision and to establish a temple of learning far from the maddening crowd of the cities and yet having all the facilities of a well developed urban campus imparting technical education at international standards, accessible to students from far and near, rich and poor alike\n",
      "helloco\n",
      "1/1 [==============================] - 0s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:53:18] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (salutaion) : I am glad I helped you\n",
      "Message  --> helloco\n",
      "I am glad I helped you\n",
      "hi hi\n",
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:53:40] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (scholarship) : Many government scholarships are supported by our university. For details and updates visit <a target='https://aamec.in'>here</a>\n",
      "Message  --> hi hi\n",
      "Many government scholarships are supported by our university. For details and updates visit <a target='https://aamec.in'>here</a>\n",
      "canteen foods \n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:54:13] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (canteen) : Our university has canteen with variety of food available\n",
      "Message  --> canteen foods \n",
      "Our university has canteen with variety of food available\n",
      "how are you\n",
      "1/1 [==============================] - 0s 319ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:55:11] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (greeting) : Hello!\n",
      "Message  --> how are you\n",
      "Hello!\n",
      "what is your name\n",
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:55:40] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HackAI (name) : I am your helper\n",
      "Message  --> what is your name?\n",
      "I am your helper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Sep/2023 10:55:50] \"GET /chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app=Flask(__name__)\n",
    "app.secret_key=\"12345\"\n",
    "\n",
    "run_with_ngrok(app)\n",
    "\n",
    "@app.route('/')\n",
    "def Home():\n",
    "    return render_template('Home.html',titleName='HackAI Chatbot | Main Page')\n",
    "\n",
    "@app.route('/chat',methods=['GET','POST'])\n",
    "def ChatBot():\n",
    "    res=0    \n",
    "    if request.method == 'POST':\n",
    "        message=str(request.form['userReply'])\n",
    "        bot_response=generate_res(message)\n",
    "        print('Message  -->',message)\n",
    "    \n",
    "        while True:\n",
    "\n",
    "           if message!='':\n",
    "               bot_response = str(bot_response)      \n",
    "               print(bot_response)\n",
    "               return jsonify({'status':'OK','answer':bot_response})\n",
    "           elif message == \"bye\":\n",
    "               bot_response='Hope to see you soon'\n",
    "               print(bot_response)\n",
    "               return jsonify({'status':'OK','answer':bot_response})\n",
    "               break\n",
    "\n",
    "    return render_template('chat.html',titleName='HackAI Chatbot | Chat')\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b215bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "while True:\n",
    "    \n",
    "    texts_p=[]\n",
    "    prediction_input=input('You :')\n",
    "    \n",
    "    prediction_input=[letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "    prediction_input=''.join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    \n",
    "    print(prediction_input)\n",
    "    \n",
    "    \n",
    "    prediction_input=tokenizer.texts_to_sequences(texts_p)\n",
    "    prediction_input=np.array( prediction_input).reshape(-1)\n",
    "    prediction_input=pad_sequences([prediction_input],input_shape)\n",
    "    \n",
    "    output=model.predict(prediction_input)\n",
    "    output=output.argmax()\n",
    "  \n",
    "    \n",
    "    response_tag=le.inverse_transform([output])[0]\n",
    "    \n",
    "#     print('Response Tag -->',response_tag)\n",
    "    print(f\"HackAI ({response_tag}) :\",random.choice(responses[response_tag]))\n",
    "    \n",
    "    if response_tag == 'goodbye':\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d8179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
